{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Big Data Final Code"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Library Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjVrxkGd1VL2",
        "outputId": "6b20a8bb-a2f3-492e-fa8d-babe276f3e92"
      },
      "outputs": [],
      "source": [
        "# %pip install --quiet mrjob==0.7.4\n",
        "# %pip install --quiet treelib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "pN1LM0mwHn7c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from treelib import Tree\n",
        "import subprocess\n",
        "import os"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating an MRJob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c-bZ4YZ2wai",
        "outputId": "85f6b77b-062d-4ec0-d1ee-246e8570ab21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting q1.py\n"
          ]
        }
      ],
      "source": [
        "%%file q1.py\n",
        "import numpy as np\n",
        "from mrjob.job import MRJob\n",
        "from mrjob.step import MRStep\n",
        "import re\n",
        "\n",
        "att_names = ['lymphatics', 'block_of_affere', 'bl_of_lymph_c', 'bl_of_lymph_s', 'by_pass', 'extravasates', 'regeneration_of', 'early_uptake_in', 'lym_nodes_dimin', 'lym_nodes_enlar',\n",
        "             'changes_in_lym', 'defect_in_node', 'changes_in_node', 'changes_in_stru', 'special_forms', 'dislocation_of', 'exclusion_of_no', 'no_of_nodes_in', 'class']\n",
        "\n",
        "\n",
        "class MRMostUsedWord(MRJob):\n",
        "\n",
        "    def steps(self):\n",
        "        return [\n",
        "            MRStep(mapper=self.mapper_get_words,reducer=self.reducer_count_words),\n",
        "            MRStep(mapper=self.mapper_entopy, reducer=self.reducer_gain),\n",
        "        ]\n",
        "\n",
        "    def mapper_get_words(self, _, line):\n",
        "        records = line.split(',')\n",
        "        if(records[8].isdigit()):\n",
        "            for i in range(0,len(records)-1):\n",
        "                yield((att_names[i],records[i],records[-1]),1)\n",
        "\n",
        "\n",
        "    def reducer_count_words(self, key, val):\n",
        "        yield (key,sum(val))\n",
        "\n",
        "    def mapper_entopy(self, key, val):\n",
        "        yield key[0], [key[1], key[2], val]\n",
        "    \n",
        "    def reducer_gain(self, key, val):\n",
        "        l = list(val)\n",
        "        total_entropy = 0\n",
        "        weighted_entropy = 0\n",
        "        split_info = 0\n",
        "        total = 0\n",
        "        target = {}\n",
        "        attribute = {}\n",
        "\n",
        "        for i in l:\n",
        "            if i[1] in target.keys():\n",
        "                target[i[1]] += i[-1]\n",
        "            else:\n",
        "                target[i[1]] = i[-1]\n",
        "\n",
        "            if i[0] in attribute.keys():\n",
        "                attribute[i[0]] += i[-1]\n",
        "            else:\n",
        "                attribute[i[0]] = i[-1]\n",
        "\n",
        "            total += i[-1]\n",
        "\n",
        "        for i in attribute.keys():\n",
        "            att_tar = {}\n",
        "            att_entropy = 0\n",
        "\n",
        "            for j in l:\n",
        "                if(j[0]==i):\n",
        "                    if j[1] in att_tar.keys():\n",
        "                        att_tar[j[1]] += j[-1]\n",
        "                    else:\n",
        "                        att_tar[j[1]] = j[-1]\n",
        "            \n",
        "            for k in att_tar.values():\n",
        "                att_entropy += (-k/attribute[i])*np.log2(k/attribute[i]) if (k/attribute[i])!=0 else 0\n",
        "            \n",
        "            weighted_entropy += (attribute[i]/total)*att_entropy\n",
        "            split_info += (-attribute[i]/total)*np.log2(attribute[i]/total) if (attribute[i]/total)!=0 else 0\n",
        "\n",
        "\n",
        "        for i in target.values():\n",
        "            total_entropy += (-i/total)*np.log2(i/total) if (i/total)!=0 else 0\n",
        "        \n",
        "        gain_ratio = (total_entropy - weighted_entropy)/split_info if split_info != 0 else 0\n",
        "\n",
        "        yield key, gain_ratio\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    MRMostUsedWord.run()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Trial of the MR Job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vhzp2dyXIKhY",
        "outputId": "fa7efc92-2d0c-4415-c2db-5202fbcbeac7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"bl_of_lymph_c\"\t0.05085493080437394\n",
            "\"bl_of_lymph_s\"\t0.14468608714865394\n",
            "\"block_of_affere\"\t0.17516765733735065\n",
            "\"by_pass\"\t0.09160735105383414\n",
            "\"changes_in_lym\"\t0.12189329255927196\n",
            "\"changes_in_node\"\t0.24603013044727012\n",
            "\"changes_in_stru\"\t0.07070000255653218\n",
            "\"defect_in_node\"\t0.08745251518655868\n",
            "\"dislocation_of\"\t0.06913674928649483\n",
            "\"early_uptake_in\"\t0.15253928934299005\n",
            "\"exclusion_of_no\"\t0.088573034933014\n",
            "\"extravasates\"\t0.029123799565949588\n",
            "\"lym_nodes_dimin\"\t0.5647091545931281\n",
            "\"lym_nodes_enlar\"\t0.12052586081609619\n",
            "\"lymphatics\"\t0.09727814243153217\n",
            "\"no_of_nodes_in\"\t0.1328311730039287\n",
            "\"regeneration_of\"\t0.38020964533911633\n",
            "\"special_forms\"\t0.1254667547340289\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Creating temp directory C:\\Users\\Ngs11\\AppData\\Local\\Temp\\q1.Ngs11.20221217.083159.832226\n",
            "Running step 1 of 2...\n",
            "Running step 2 of 2...\n",
            "job output is in C:\\Users\\Ngs11\\AppData\\Local\\Temp\\q1.Ngs11.20221217.083159.832226\\output\n",
            "Streaming final output from C:\\Users\\Ngs11\\AppData\\Local\\Temp\\q1.Ngs11.20221217.083159.832226\\output...\n",
            "Removing temp directory C:\\Users\\Ngs11\\AppData\\Local\\Temp\\q1.Ngs11.20221217.083159.832226...\n"
          ]
        }
      ],
      "source": [
        "!python q1.py \"lymph.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lym_nodes_dimin 0.5647091545931281\n"
          ]
        }
      ],
      "source": [
        "cmd = subprocess.run([\"python\", \"q1.py\", \"lymph.csv\"], capture_output=True)\n",
        "stdout = cmd.stdout.decode()\n",
        "best_val = 0\n",
        "best_feature = None\n",
        "for item in stdout.strip().replace('\"', '').split('\\n'):\n",
        "    # print(item)\n",
        "    att, val = item.split('\\t')\n",
        "    # print(att, val)\n",
        "    if(float(val)>best_val):\n",
        "        best_feature = att\n",
        "        best_val = float(val)\n",
        "print(best_feature, best_val)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Building a Decision Tree"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* logarithm to the base 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "JnN9zZCLUMor"
      },
      "outputs": [],
      "source": [
        "def log(val):\n",
        "    if val == 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return np.log2(val)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Entropy Calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "def entropy(target_col):  \n",
        "    \n",
        "    elements, counts = np.unique(target_col,return_counts = True)  \n",
        "    entropy = np.sum([(-counts[i]/np.sum(counts))*log(counts[i]/np.sum(counts)) for i in range(len(elements))])  \n",
        "    return entropy"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Gain Ratio Calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "def GainRatio(data,split_attribute_name,target_attribute_name=\"Loan_Status\"):  \n",
        "         \n",
        "    #Calculate the entropy of the total dataset  \n",
        "    total_entropy = entropy(data[target_attribute_name])  \n",
        "    # print(total_entropy)\n",
        "    ##Calculate the entropy of the dataset  \n",
        "      \n",
        "    #Calculate the values and the corresponding counts for the split attribute   \n",
        "    vals, counts= np.unique(data[split_attribute_name],return_counts=True)  \n",
        "      \n",
        "    #Calculate the weighted entropy  \n",
        "    Weighted_Entropy = np.sum([(counts[i]/np.sum(counts))*entropy(data[data[split_attribute_name]==vals[i]][target_attribute_name]) for i in range(len(vals))])  \n",
        "    # print(Weighted_Entropy)\n",
        "    #Calculate split information gain\n",
        "    Split_Info = np.sum([(-counts[i]/np.sum(counts))*log(counts[i]/np.sum(counts)) for i in range(len(vals))])\n",
        "\n",
        "    #Calculate the information gain  \n",
        "    Information_Gain = total_entropy - Weighted_Entropy  \n",
        "\n",
        "    #Calculate the gain ratio\n",
        "    Gain_Ratio = Information_Gain/Split_Info if Split_Info != 0 else 0\n",
        "    # print(Gain_Ratio)\n",
        "\n",
        "    return Gain_Ratio "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Add node function to add a node to the tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "xkjiHAaXqaQj"
      },
      "outputs": [],
      "source": [
        "def add_node(tree, best_feature, pid, path):\n",
        "    if(pid == None):\n",
        "        tree.create_node(tag = best_feature, identifier = best_feature)\n",
        "        return best_feature\n",
        "    else:\n",
        "        tree.create_node(str(path) + \":\" + best_feature, pid + \"/\" + str(path) + \"/\" + best_feature, pid)\n",
        "        return pid + \"/\" + str(path) + \"/\" + best_feature"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### C45 Algo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [],
      "source": [
        "def C45(tree, data, features, target_attribute_name=\"class\", parent_node_class = None, pid = None, path = None, lvl = 0):  \n",
        "  \n",
        "    #Define the stopping criteria --> If one of this is satisfied, we want to return a leaf node#  \n",
        "      \n",
        "    #If all target_values have the same value, return this value  \n",
        "    if len(np.unique(data[target_attribute_name])) <= 1:\n",
        "        best_feature = np.unique(data[target_attribute_name])[0]  \n",
        "        pid = add_node(tree, best_feature, pid, path)\n",
        "        \n",
        "    #If the feature space is empty, return the mode target feature value of the direct parent node \n",
        "    elif len(features) ==0:\n",
        "        best_feature = parent_node_class \n",
        "        pid = add_node(tree, best_feature, pid, path) \n",
        "      \n",
        "    #If none of the above holds true, grow the tree!  \n",
        "    else:  \n",
        "        #Set the default value for this node --> The mode target feature value of the current node  \n",
        "        parent_node_class = np.unique(data[target_attribute_name])[np.argmax(np.unique(data[target_attribute_name],return_counts=True)[1])]  \n",
        "          \n",
        "        # #Select the feature which best splits the dataset  \n",
        "        # item_values = [GainRatio(data,feature,target_attribute_name) for feature in features] #Return the information gain values for the features in the dataset  \n",
        "        # # print(features)\n",
        "        \n",
        "        # best_feature_index = np.argmax(item_values)  \n",
        "        # best_feature = features[best_feature_index]\n",
        "\n",
        "        fname = 'lymph' + str(lvl) + '.csv'\n",
        "\n",
        "        data.to_csv(fname, index=False)\n",
        "\n",
        "        cmd = subprocess.run([\"python\", \"q1.py\", fname], capture_output=True)\n",
        "        stdout = cmd.stdout.decode()\n",
        "        # print(stdout)\n",
        "        best_val = 0\n",
        "        best_feature = None\n",
        "        for item in stdout.strip().replace('\"', '').split('\\n'):\n",
        "            att, val = item.split('\\t')\n",
        "            if(float(val)>best_val):\n",
        "                best_feature = att\n",
        "                best_val = float(val)\n",
        "        # print(best_feature, best_val)\n",
        "          \n",
        "        #Create the tree structure. The root gets the name of the feature (best_feature) with the maximum information  \n",
        "        #gain in the first run  \n",
        "        \n",
        "        pid = add_node(tree, best_feature, pid, path)\n",
        "        # for node in  tree.all_nodes_itr():\n",
        "        #     print(node.identifier)\n",
        "          \n",
        "        #Remove the feature with the best inforamtion gain from the feature space  \n",
        "        features = [i for i in features if i != best_feature]  \n",
        "          \n",
        "        #Grow a branch under the root node for each possible value of the root node feature  \n",
        "          \n",
        "        for val in np.unique(data[best_feature]): \n",
        "            #Split the dataset along the value of the feature with the largest information gain and therwith create sub_datasets  \n",
        "            sub_data = data[data[best_feature] == val]\n",
        "            # print(value)  \n",
        "              \n",
        "            #Call the ID3 algorithm for each of those sub_datasets with the new parameters --> Here the recursion comes in!  \n",
        "            C45(tree, sub_data, features, target_attribute_name, parent_node_class, pid, val, lvl+1)\n",
        "\n",
        "        os.remove(fname)\n",
        "        del data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generating Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pU6vDjtWHqJF",
        "outputId": "6cb31969-2331-4a8f-85cd-0c33337779d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['lymphatics', 'block_of_affere', 'bl_of_lymph_c', 'bl_of_lymph_s', 'by_pass', 'extravasates', 'regeneration_of', 'early_uptake_in', 'lym_nodes_dimin', 'lym_nodes_enlar', 'changes_in_lym', 'defect_in_node', 'changes_in_node', 'changes_in_stru', 'special_forms', 'dislocation_of', 'exclusion_of_no', 'no_of_nodes_in', 'class']\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv(\"lymph0.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkv19fn0zBi6",
        "outputId": "3a531eef-806c-4f7c-aeae-38672f12da0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lym_nodes_dimin\n",
            "├── 1:changes_in_node\n",
            "│   ├── lac_central:exclusion_of_no\n",
            "│   │   ├── no:bl_of_lymph_c\n",
            "│   │   │   ├── no:malign_lymph\n",
            "│   │   │   └── yes:metastases\n",
            "│   │   └── yes:lym_nodes_enlar\n",
            "│   │       ├── 2:changes_in_stru\n",
            "│   │       │   ├── diluted:metastases\n",
            "│   │       │   └── faint:malign_lymph\n",
            "│   │       ├── 3:malign_lymph\n",
            "│   │       └── 4:malign_lymph\n",
            "│   ├── lac_margin:block_of_affere\n",
            "│   │   ├── no:extravasates\n",
            "│   │   │   ├── no:lymphatics\n",
            "│   │   │   │   ├── arched:early_uptake_in\n",
            "│   │   │   │   │   ├── no:changes_in_lym\n",
            "│   │   │   │   │   │   ├── oval:metastases\n",
            "│   │   │   │   │   │   └── round:changes_in_stru\n",
            "│   │   │   │   │   │       ├── drop_like:malign_lymph\n",
            "│   │   │   │   │   │       └── faint:metastases\n",
            "│   │   │   │   │   └── yes:no_of_nodes_in\n",
            "│   │   │   │   │       ├── 2:malign_lymph\n",
            "│   │   │   │   │       ├── 3:malign_lymph\n",
            "│   │   │   │   │       └── 4:metastases\n",
            "│   │   │   │   ├── deformed:metastases\n",
            "│   │   │   │   └── displaced:malign_lymph\n",
            "│   │   │   └── yes:malign_lymph\n",
            "│   │   └── yes:no_of_nodes_in\n",
            "│   │       ├── 1:metastases\n",
            "│   │       ├── 2:metastases\n",
            "│   │       ├── 3:by_pass\n",
            "│   │       │   ├── no:changes_in_stru\n",
            "│   │       │   │   ├── grainy:metastases\n",
            "│   │       │   │   └── stripped:malign_lymph\n",
            "│   │       │   └── yes:metastases\n",
            "│   │       ├── 4:changes_in_stru\n",
            "│   │       │   ├── diluted:malign_lymph\n",
            "│   │       │   ├── faint:malign_lymph\n",
            "│   │       │   └── grainy:metastases\n",
            "│   │       ├── 6:metastases\n",
            "│   │       └── 7:metastases\n",
            "│   ├── lacunar:exclusion_of_no\n",
            "│   │   ├── no:early_uptake_in\n",
            "│   │   │   ├── no:changes_in_stru\n",
            "│   │   │   │   ├── coarse:metastases\n",
            "│   │   │   │   ├── drop_like:malign_lymph\n",
            "│   │   │   │   └── faint:metastases\n",
            "│   │   │   └── yes:metastases\n",
            "│   │   └── yes:special_forms\n",
            "│   │       ├── chalices:changes_in_lym\n",
            "│   │       │   ├── oval:malign_lymph\n",
            "│   │       │   └── round:metastases\n",
            "│   │       ├── no:dislocation_of\n",
            "│   │       │   ├── no:malign_lymph\n",
            "│   │       │   └── yes:metastases\n",
            "│   │       └── vesicles:early_uptake_in\n",
            "│   │           ├── no:metastases\n",
            "│   │           └── yes:malign_lymph\n",
            "│   └── no:defect_in_node\n",
            "│       ├── lacunar:malign_lymph\n",
            "│       └── no:dislocation_of\n",
            "│           ├── no:normal\n",
            "│           └── yes:metastases\n",
            "├── 2:no_of_nodes_in\n",
            "│   ├── 1:metastases\n",
            "│   ├── 7:fibrosis\n",
            "│   └── 8:malign_lymph\n",
            "└── 3:fibrosis\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tree = Tree()\n",
        "C45(tree, data, data.columns[:-1], 'class') \n",
        "tree.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "dd3443abd388962b9364966be6f2006c33110f8883e28a48b8a15f07387372d6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
